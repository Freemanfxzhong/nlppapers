# Achieving Human Parity on Automatic Chinese to English News Translation

|||
| --- | --- |
| Title | Achieving Human Parity on Automatic Chinese to English News Translation |
| Authors | Hany Hassan, Anthony Aue, Chang Chen, Vishal Chowdhary, Jonathan Clark, Christian Federmann, Xuedong Huang, Marcin Junczys-Dowmunt, William Lewis, Mu Li, Shujie Liu, Tie-Yan Liu, Renqian Luo, Arul Menezes, Tao Qin, Frank Seide, Xu Tan, Fei Tian, Lijun Wu, Shuangzhi Wu, Yingce Xia, Dongdong Zhang, Zhirui Zhang, Ming Zhou |
| Year | 2018 |
| URL | https://arxiv.org/abs/1803.05567 |

In this paper, Microsoft presents a Machine Translation system that is judged to perform
as well as humans on Chinese-to-English news translation. The main contributions of the
paper lie in the evaluation setup and the architecture and training of the MT system.

With respect to the evaluation, Hassan et al. argue that reference-based MT evaluation
is broken: differences from the reference are not always incorrect and references
are often of low quality. They therefore have humans evaluate their systems, by scoring
the output of the translations on a scale from 0 to 100. In this setup, human parity is
achieved when the scores given to system translations are not significantly different 
from the scores given to human translations.

Starting from an initial Transformer system, Hassan et al. introduce a number of advancements in the 
architecture and the training of their system: 

- Dual unsupervised learning: to enhance Chinese-to-English translation quality, they
have their Chinese-to-English system translate a monolingual Chinese corpus to English,
and their English-to-Chinese system reconstruct the original sentences. The 
Chinese-to-English system is optimized by maximizing the expected reconstruction 
log-likelihood.
- Dual supervised learning: they jointly train the Zh-En and En-Zh models and introduce
an additional loss term that is meant to enhance the probabilistic correlations between
the two: p(x)p(y|x) = p(y)p(x|y).
- Back-translation: in their iterative training procedure, they use the previous system state to back-translate
monolingual data and thereby generate additional bilingual training data for the next iteration.
- Deliberation networks: deliberation networks add a second decoder on top of the first. This
second decoder takes the output from the encoder and the first-pass decoder to overcome
the limitations of purely left-to-right target generation.
- Agreement regularization: unsatisfactory translations with bad suffixes generated by a 
left-to-right model often have low predictions under a right-to-left model. Therefore, 
Hassan et al. minimize the Kullback-Leibler divergence between a left-to-right and a right-to-left model. 
- Data selection: noisy training data is rejected by keeping only parallel training sentences
where the embedding similarity between the source and target sentence in a bilingual vector space
exceeds a given threshold.
- System combination: the n-best hypotheses from all systems are taken and re-ranked
using k-best MIRA on the validation set, based on features such as the system score, the cross-lingual
sentence similarity, etc.

In this way, Hassan et al. achieve human parity on the Chinese-to-English news
translation test set of WMT 2017. Obviously, they do not claim that this result generalizes
to other language pairs and domains.